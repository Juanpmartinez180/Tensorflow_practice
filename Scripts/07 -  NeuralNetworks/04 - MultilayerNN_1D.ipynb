{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Neural Network\n",
    "\n",
    "### 1-D case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "session = tf.Session()\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 25\n",
    "data_1d = np.random.normal(size = data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tensorflow variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input_1d  = tf.placeholder(shape = [data_size], dtype= tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional layer. The following function took a 1-d array and a given filter to return the convolution of both values. TF convolution function receive as an input data an 4-d array, so before feed this function we neeed to expand dimentions of the 1-d given array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer_1d(input_1d, my_filter):\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    convolution = tf.nn.conv2d(input_4d, filter = my_filter, strides = [1,1,1,1], padding = 'VALID')\n",
    "    output = tf.squeeze(convolution)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution. First we define the filter using a random distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = tf.Variable(tf.random_normal(shape = [1, 5, 1, 1]))\n",
    "my_conv_output = convolutional_layer_1d(x_input_1d, my_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation function using ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(input_1d):\n",
    "    return tf.nn.relu(input_1d)\n",
    "\n",
    "my_activation_output = activation(my_conv_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max pooling layer. This function return the pooling using a given windom of size $width$. In this case the idea is to take the output of the activation function and return a small-size tensor with the most relevant data of the original output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(input_1d, width):\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    pooling = tf.nn.max_pool(input_4d, ksize=[1,1,width, 1], strides = [1,1,1,1], padding = 'VALID')\n",
    "    output = tf.squeeze(pooling)\n",
    "    return(output)\n",
    "\n",
    "my_maxpool_output = max_pool(my_activation_output, width = 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully connected layer. This layer convert the maxpooling layer output in to a 1-d array to feed the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(input_layer, num_output):\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(input_layer), [num_output]]))\n",
    "    weight = tf.random_normal(weight_shape, stddev = 0.1)\n",
    "    bias = tf.random_normal(shape = [num_output])\n",
    "    input_layer_2d = tf.expand_dims(input_layer, 0)\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
    "    full_output_1d = tf.squeeze(full_output)\n",
    "    return(full_output_1d)\n",
    "\n",
    "my_full_output = fully_connected(my_maxpool_output, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function ejecution.\n",
    "We feed the main functions to see if the result is the expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {x_input_1d: data_1d}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution\n",
    "- Using the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09941728, -0.67428829, -0.04953568,  0.14211985,  1.44992216,\n",
       "       -0.77852435,  1.0563369 ,  0.79722011,  0.43687146, -1.15331551,\n",
       "        0.47681568,  0.06056182, -0.07555616,  0.18627288, -1.20940125,\n",
       "        0.60814375,  0.41341099,  3.10559723, -0.62372542, -0.17035176,\n",
       "        0.37091793, -0.09960386, -0.55126644, -1.03136013,  0.58911361])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And the filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.89985293]],\n",
       "\n",
       "        [[ 0.28642622]],\n",
       "\n",
       "        [[ 0.44073153]],\n",
       "\n",
       "        [[-0.80505633]],\n",
       "\n",
       "        [[-0.7751633 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(my_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolution result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Size 25, Operation: Convolution with size 5 filter and stride size 1, Result size: 21\n",
      "[-1.5427676  -1.1220975   0.44308093 -1.268324    0.56683403  0.4956669\n",
      "  1.9303097  -0.09659897  0.28274065 -0.9581152   1.2006338   0.6171773\n",
      " -1.3577082  -2.650922   -2.7485833   2.668571    0.8362589   2.3194494\n",
      "  0.06092913  1.1523236   0.4359257 ]\n"
     ]
    }
   ],
   "source": [
    "print('Input: Size 25, Operation: Convolution with size 5 filter and stride size 1, Result size: 21')\n",
    "print(session.run(my_conv_output, feed_dict = feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation function\n",
    "- Using the convolution result as input data (size = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5427676  -1.1220975   0.44308093 -1.268324    0.56683403  0.4956669\n",
      "  1.9303097  -0.09659897  0.28274065 -0.9581152   1.2006338   0.6171773\n",
      " -1.3577082  -2.650922   -2.7485833   2.668571    0.8362589   2.3194494\n",
      "  0.06092913  1.1523236   0.4359257 ]\n"
     ]
    }
   ],
   "source": [
    "print(session.run(my_conv_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Activation function result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.44308093 0.         0.56683403 0.4956669\n",
      " 1.9303097  0.         0.28274065 0.         1.2006338  0.6171773\n",
      " 0.         0.         0.         2.668571   0.8362589  2.3194494\n",
      " 0.06092913 1.1523236  0.4359257 ]\n"
     ]
    }
   ],
   "source": [
    "print(session.run(my_activation_output, feed_dict = feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Pooling\n",
    "- Using the activaction function result as input data (size = 21). \n",
    "- Max pooling result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size = 21, Operation = MaxPooling with window size:5 and stride size:1, Result size: 17\n",
      "[0.56683403 0.56683403 1.9303097  1.9303097  1.9303097  1.9303097\n",
      " 1.9303097  1.2006338  1.2006338  1.2006338  1.2006338  2.668571\n",
      " 2.668571   2.668571   2.668571   2.668571   2.3194494 ]\n"
     ]
    }
   ],
   "source": [
    "print('Input size = 21, Operation = MaxPooling with window size:5 and stride size:1, Result size: 17')\n",
    "print(session.run(my_maxpool_output, feed_dict = feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully connected layer\n",
    "- Using the maxpooling result as input data (size: 17)\n",
    "- Fully connected layer result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size = 21, Operation = Fully connected conversion with output size:5, Result size: 5\n",
      "[-0.25489312 -0.794742   -2.1049075  -0.07278401 -1.6144413 ]\n"
     ]
    }
   ],
   "source": [
    "print('Input size = 21, Operation = Fully connected conversion with output size:5, Result size: 5')\n",
    "print(session.run(my_full_output, feed_dict = feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-D case\n",
    "\n",
    "We're going to replicate all the operations but in this case using a 2-D input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()   #Restart the session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = [10, 10]\n",
    "data_2d = np.random.normal(size = data_size)\n",
    "x_input_2d = tf.placeholder(shape = data_size, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_2d(input_2d, my_filter):\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    convolution = tf.nn.conv2d(input_4d, filter = my_filter, strides = [1,2,2,1], padding = 'VALID')\n",
    "    output = tf.squeeze(convolution)\n",
    "    \n",
    "    return(output)\n",
    "my_filter = tf.Variable(tf.random_normal(shape = [2,2,1,1]))\n",
    "my_conv_output = conv_layer_2d(x_input_2d, my_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_2d(input_2d):\n",
    "    return(tf.nn.relu(input_2d))\n",
    "my_activation_output = activation_2d(my_conv_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2d(input_2d, widht, height):\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    pooling = tf.nn.max_pool(input_4d, ksize=[1, height, widht, 1], strides = [1,1,1,1], padding = 'VALID')\n",
    "    output = tf.squeeze(pooling)\n",
    "    return(output)\n",
    "my_maxpool_output = max_pool_2d(my_activation_output, widht = 2, height = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_2d(input_layer, num_output):\n",
    "    flat_input = tf.reshape(input_layer, [-1])\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(flat_input), [num_output]]))\n",
    "    weight = tf.random_normal(weight_shape, stddev = 0.1)\n",
    "    bias = tf.random_normal(shape = [num_output])\n",
    "    input_layer_2d = tf.expand_dims(flat_input, 0)\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
    "    full_output_1d = tf.squeeze(full_output)\n",
    "    return(full_output_1d)\n",
    "my_full_output = fully_connected_2d(my_maxpool_output, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions ejecutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {x_input_2d: data_2d}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution\n",
    "- Input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.69794141e-01, -2.25160742e-01, -8.24612638e-01,\n",
       "         5.79559523e-01, -1.14428570e+00, -3.52926814e-01,\n",
       "        -1.80544371e+00,  8.40501244e-01,  2.98406345e-01,\n",
       "         2.77286718e-01],\n",
       "       [ 7.08391718e-02,  5.35104511e-01,  1.19381926e+00,\n",
       "        -3.43527567e-01,  1.96870853e-01,  1.61432893e-01,\n",
       "        -1.42643910e-01,  4.95835046e-01,  1.89082610e-02,\n",
       "         1.22827731e+00],\n",
       "       [ 8.51439820e-01,  3.94907971e-01,  4.63162178e-01,\n",
       "         3.99733083e-02, -4.66718407e-01,  6.52422735e-01,\n",
       "         2.11419782e-01, -2.82728140e-01,  1.05665841e-01,\n",
       "         5.67966292e-01],\n",
       "       [ 5.30940216e-01,  8.07084817e-01, -1.80624890e+00,\n",
       "        -5.50062741e-01,  1.86615024e-01, -1.29533443e+00,\n",
       "         1.16834706e+00, -1.83152883e-01, -8.28473859e-02,\n",
       "         2.94814013e-01],\n",
       "       [ 2.92139126e-01, -1.64149137e-01, -1.64592971e-01,\n",
       "        -1.84087750e-01,  7.17392022e-01, -1.66528420e+00,\n",
       "         1.19868783e-01,  2.20309968e+00,  1.53871607e+00,\n",
       "         2.40982408e-01],\n",
       "       [-5.71418984e-02, -1.05104785e+00,  7.51265288e-01,\n",
       "        -2.00547615e+00,  2.15365085e+00, -7.17190177e-01,\n",
       "         2.04494266e-01, -1.19300244e+00, -2.07674453e-03,\n",
       "         3.95519165e-01],\n",
       "       [-5.30273230e-01,  4.75485398e-04, -5.97573185e-01,\n",
       "         8.53513206e-02,  2.64027877e-01,  8.57848790e-01,\n",
       "        -1.58075367e+00, -5.67824798e-01, -1.99804234e+00,\n",
       "        -9.45161046e-02],\n",
       "       [ 4.68132994e-01,  4.46179177e-01, -2.35178053e+00,\n",
       "        -1.90192860e+00,  1.79558109e-01,  1.06794494e+00,\n",
       "        -1.74713045e+00,  8.19647332e-01,  2.33074362e-01,\n",
       "         1.03701955e+00],\n",
       "       [ 1.17473023e+00,  1.01650921e+00, -1.29066532e+00,\n",
       "        -4.45906183e-01,  2.94713696e-01,  3.74396401e-01,\n",
       "         3.09123660e-01,  3.60077650e-01, -6.52572053e-01,\n",
       "         8.29557204e-01],\n",
       "       [ 5.28051015e-01,  1.10387369e+00,  1.59897589e+00,\n",
       "        -5.68292089e-02, -5.04617316e-01, -3.60071174e-01,\n",
       "         6.27716151e-01,  4.19735465e-01,  9.93817763e-01,\n",
       "         1.85943066e+00]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filter to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.05529318]]\n",
      "\n",
      "  [[-0.8814632 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.27901518]]\n",
      "\n",
      "  [[ 0.9101391 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(session.run(my_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolution operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Size [10,10], Operation: Convolution with size: [2,2] filter and stride size: [2,2], Result size: [5,5]\n",
      "[[ 0.7422907  -0.5360199   0.44967714 -0.42922068  0.8952607 ]\n",
      " [ 0.5816817  -1.0142298  -1.7277591   0.42019647 -0.24959272]\n",
      " [-0.8116984  -1.4624821   1.4557121  -2.9640646   0.23206139]\n",
      " [ 0.5069617  -2.4954777   0.28051472  0.67162883  0.9816976 ]\n",
      " [ 0.320952    0.716101   -0.78223175  0.2568572   1.2023238 ]]\n"
     ]
    }
   ],
   "source": [
    "print('Input: Size [10,10], Operation: Convolution with size: [2,2] filter and stride size: [2,2], Result size: [5,5]')\n",
    "print(session.run(my_conv_output, feed_dict = feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: [5,5], Operation: ReLu to convolution output, Result size: [5,5]\n",
      "[[0.7422907  0.         0.44967714 0.         0.8952607 ]\n",
      " [0.5816817  0.         0.         0.42019647 0.        ]\n",
      " [0.         0.         1.4557121  0.         0.23206139]\n",
      " [0.5069617  0.         0.28051472 0.67162883 0.9816976 ]\n",
      " [0.320952   0.716101   0.         0.2568572  1.2023238 ]]\n"
     ]
    }
   ],
   "source": [
    "print('Input size: [5,5], Operation: ReLu to convolution output, Result size: [5,5]')\n",
    "print(session.run(my_activation_output, feed_dict = feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: [5, 5], Operation = MaxPooling with window size:[2,2] and stride size:1, Result size: [4,4]\n",
      "[[0.7422907  0.44967714 0.44967714 0.8952607 ]\n",
      " [0.5816817  1.4557121  1.4557121  0.42019647]\n",
      " [0.5069617  1.4557121  1.4557121  0.9816976 ]\n",
      " [0.716101   0.716101   0.67162883 1.2023238 ]]\n"
     ]
    }
   ],
   "source": [
    "print('Input size: [5, 5], Operation = MaxPooling with window size:[2,2] and stride size:1, Result size: [4,4]')\n",
    "print(session.run(my_maxpool_output, feed_dict = feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size:[4,4], Operation = Fully connected conversion with output size:5, Result size: 5\n",
      "[ 1.0684043   0.2986397  -0.06971306 -0.34995604  0.52973837]\n"
     ]
    }
   ],
   "source": [
    "print('Input size:[4,4], Operation = Fully connected conversion with output size:5, Result size: 5')\n",
    "print(session.run(my_full_output, feed_dict = feed_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
